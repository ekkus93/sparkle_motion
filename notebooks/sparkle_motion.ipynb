{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eda5d3",
   "metadata": {},
   "source": [
    "# sparkle_motion — Colab / Drive setup\n",
    "This notebook contains the recommended Colab setup steps and a small smoke-test harness for running the orchestrator in a GPU environment.\n",
    "- Use the cells below to mount Google Drive (Colab only).\n",
    "- Use the installation cell to install the ML stack from `requirements-ml.txt` (optional; heavy).\n",
    "- The smoke-test cell is a safe stub that checks imports and shows how to run the orchestrator in simulation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c497420",
   "metadata": {},
   "source": [
    "## Notes and expectations\n",
    "- This notebook is intended for Google Colab (A100) runs. If you are running locally, skip the Drive mount and run the commands in a terminal.\n",
    "- Before installing the heavy ML dependencies, ensure you have sufficient disk and GPU (Colab or a VM). The requirements are listed in `requirements-ml.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56db335",
   "metadata": {},
   "source": [
    "## Configure workspace inputs\n",
    "Set these before running the helper so it knows where to create directories and which model snapshots to pull. Provide one or more repo IDs via `HF_MODELS`; set `DRY_RUN = True` or leave the list empty to skip downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2587a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured workspace 'SparkleMotion' (repo root: /home/phil/work/sparkle_motion/notebooks)\n",
      "Models to manage: ['stabilityai/stable-diffusion-xl-base-1.0']\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Workspace configuration (edit these as needed)\n",
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE_NAME = \"SparkleMotion\"          # Folder created under MyDrive/\n",
    "HF_MODELS = [\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "]\n",
    "DRY_RUN = False                              # True = skip download/smoke actions\n",
    "MOUNT_POINT = \"/content/drive\"             # Default Colab mount\n",
    "REPO_ROOT = Path.cwd()                       # Assumes notebook is opened from repo root\n",
    "\n",
    "print(f\"Configured workspace '{WORKSPACE_NAME}' (repo root: {REPO_ROOT})\")\n",
    "print(f\"Models to manage: {HF_MODELS or '[none specified]'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e641fa1",
   "metadata": {},
   "source": [
    "## Load secrets from `.env`\n",
    "Run the next cell once the bootstrap script has created a `.env` file (either in the\n",
    "repo root, `/content`, or your Drive workspace). It installs `python-dotenv` if\n",
    "necessary and loads the variables into the current kernel so the ADK clients can\n",
    "reuse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb81eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0a: Load secrets from .env using python-dotenv\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _ensure_python_dotenv_installed() -> None:\n",
    "    if importlib.util.find_spec(\"dotenv\") is None:\n",
    "        print(\"Installing python-dotenv...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-dotenv\"])\n",
    "\n",
    "\n",
    "_ensure_python_dotenv_installed()\n",
    "from dotenv import load_dotenv  # type: ignore  # imported after ensuring package\n",
    "\n",
    "candidate_paths = [\n",
    "    REPO_ROOT / \".env.local\",\n",
    "    REPO_ROOT / \".env\",\n",
    "    Path(\"/content/.env\"),\n",
    "    Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \".env\",\n",
    "]\n",
    "\n",
    "env_path = next((path for path in candidate_paths if path.exists()), None)\n",
    "if env_path is None:\n",
    "    print(\n",
    "        \"No .env file found. Run scripts/bootstrap_adk_projects.sh --profile local-colab \"\n",
    "        \"and re-run this cell once the file exists.\"\n",
    "    )\n",
    "else:\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"Loaded environment variables from {env_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Mount Google Drive (Colab-only)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "if not in_colab:\n",
    "    print(\"Not running inside Google Colab; skipping Drive mount.\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "\n",
    "    mount_target = Path(MOUNT_POINT)\n",
    "    mount_target.mkdir(parents=True, exist_ok=True)\n",
    "    if os.path.ismount(mount_target):\n",
    "        print(f\"Google Drive already mounted at {mount_target}.\")\n",
    "    else:\n",
    "        print(f\"Mounting Google Drive at {mount_target}...\")\n",
    "        drive.mount(str(mount_target), force_remount=False)\n",
    "\n",
    "    workspace_root = mount_target / \"MyDrive\" / WORKSPACE_NAME\n",
    "    workspace_root.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Workspace directory ready at {workspace_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35371e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install ML dependencies from requirements-ml.txt (Colab / heavy)\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "def sh(cmd):\n",
    "    print('Running:', cmd)\n",
    "    return subprocess.check_call(cmd, shell=True)\n",
    "\n",
    "\n",
    "if importlib.util.find_spec('google.colab'):\n",
    "    print('Detected Colab.\\n')\n",
    "    print('If you need a CUDA-optimized torch wheel, install it first as recommended in the repo notebook.\\n')\n",
    "    # The repository contains requirements-ml.txt at the repo root.\n",
    "    # If you placed the repository under Drive, adjust the path accordingly (e.g. /content/drive/MyDrive/sparkle_motion/requirements-ml.txt).\n",
    "    req_path = 'requirements-ml.txt'\n",
    "    try:\n",
    "        sh(f'pip install -r \"{req_path}\"')\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        print('pip install failed:', exc)\n",
    "else:\n",
    "    print('Not running in Colab — to install locally run:\\n    pip install -r requirements-ml.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b720abb",
   "metadata": {},
   "source": [
    "## Prepare Drive workspace and download models\n",
    "Use the helper script added to the repo (`scripts/colab_drive_setup.py`) to create Drive folders, optionally download Hugging Face weights, and write a smoke artifact in `outputs/colab_smoke.json`.\n",
    "- When running locally (outside Colab), pass `--local-root /path/to/workspace` so the helper skips the Drive mount and uses your filesystem directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777417cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Force-set REPO_ROOT to /home/phil/work/sparkle_motion\n"
     ]
    }
   ],
   "source": [
    "# Run once before Cell 4\n",
    "REPO_ROOT = Path(\"/home/phil/work/sparkle_motion\")\n",
    "print(\"Force-set REPO_ROOT to\", REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d0ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper script not found at /home/phil/work/sparkle_motion/notebooks/scripts/colab_drive_setup.py. Ensure you're running the notebook from the repo root.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Invoke Drive helper (creates folders, optional download)\n",
    "import importlib.util\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "helper_path = REPO_ROOT / \"scripts\" / \"colab_drive_setup.py\"\n",
    "if not helper_path.exists():\n",
    "    print(f\"Helper script not found at {helper_path}. Ensure you're running the notebook from the repo root.\")\n",
    "else:\n",
    "    in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "    if not in_colab:\n",
    "        print(\"Not running inside Google Colab. Run the helper manually from a terminal:\")\n",
    "        local_root = (REPO_ROOT / \"colab_drive_workspace\").resolve()\n",
    "        cmd_parts = [\n",
    "            f\"PYTHONPATH=\\\"{REPO_ROOT / 'src'}\\\"\",\n",
    "            \"python\",\n",
    "            str(helper_path),\n",
    "            WORKSPACE_NAME,\n",
    "            \"--local-root\",\n",
    "            str(local_root),\n",
    "        ]\n",
    "        for repo_id in HF_MODELS:\n",
    "            cmd_parts.extend([\"--model\", repo_id])\n",
    "        if DRY_RUN:\n",
    "            cmd_parts.append(\"--dry-run\")\n",
    "        print(\"  \" + \" \".join(cmd_parts))\n",
    "        print(\"Adjust --local-root to a writable directory if you prefer a different location.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            str(helper_path),\n",
    "            WORKSPACE_NAME,\n",
    "            \"--mount-point\",\n",
    "            str(MOUNT_POINT),\n",
    "        ]\n",
    "        for repo_id in HF_MODELS:\n",
    "            cmd.extend([\"--model\", repo_id])\n",
    "        if DRY_RUN:\n",
    "            cmd.append(\"--dry-run\")\n",
    "        print(\"Running helper:\", \" \".join(cmd))\n",
    "        subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8e69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No smoke artifact found at /content/drive/MyDrive/SparkleMotion/outputs/colab_smoke.json. Run the helper once to generate it.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4b: Inspect smoke artifact with per-model status\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "smoke_path = Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \"outputs\" / \"colab_smoke.json\"\n",
    "if smoke_path.exists():\n",
    "    data = json.loads(smoke_path.read_text(encoding=\"utf-8\"))\n",
    "    status = \"OK\" if data.get(\"ok\") else \"FAILED\"\n",
    "    print(f\"Smoke status: {status}\")\n",
    "    for model in data.get(\"models\", []):\n",
    "        sample = model.get(\"sample_file\") or \"n/a\"\n",
    "        print(\n",
    "            f\"- {model['repo_id']}: {model['status']} \"\n",
    "            f\"({model.get('files_present', 0)} files, sample={sample})\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"No smoke artifact found at {smoke_path}. Run the helper once to generate it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c97200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Smoke-test stub for the orchestrator (safe, non-destructive)\n",
    "# This cell attempts to import the orchestrator package and reports what is available.\n",
    "try:\n",
    "    import sparkle_motion.orchestrator as orchestrator_mod\n",
    "    print('Imported sparkle_motion.orchestrator ->', orchestrator_mod)\n",
    "    if hasattr(orchestrator_mod, 'Runner'):\n",
    "        print('Runner class is available. You can instantiate it for a simulation run.')\n",
    "        print('Example (local):')\n",
    "        print(\"  from sparkle_motion.orchestrator import Runner\")\n",
    "        print(\"  r = Runner(run_dir='runs')\")\n",
    "        print(\"  # then use r.run(...) or similar per your orchestrator API\")\n",
    "    else:\n",
    "        print('Runner class not found — inspect src/sparkle_motion/orchestrator.py for usage.')\n",
    "except Exception as e:\n",
    "    print('Could not import orchestrator module:', e)\n",
    "    print('If you want to run the orchestrator, ensure the package is on PYTHONPATH (e.g., pip install -e .) or run via the repository root.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08966a60",
   "metadata": {},
   "source": [
    "## Quickstart: Launch the control panel\n",
    "Run this cell after the FunctionTools are live (script_agent + production_agent listening on localhost). It imports `create_control_panel`, instantiates the widgets with the `local-colab` profile, and stores the panel in `control_panel` so later helpers (status polling, final deliverable preview) can reuse the same run metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "REPO_ROOT = Path(\"/home/phil/work/sparkle_motion\")  # or Path.cwd() if already in repo\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.append(str(REPO_ROOT))\n",
    "SRC_PATH = REPO_ROOT / \"src\"\n",
    "if str(SRC_PATH) not in sys.path:\n",
    "    sys.path.append(str(SRC_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1289a2b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sparkle_motion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Quickstart cell: import and display the ipywidgets control panel\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnotebooks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrol_panel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_control_panel\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLaunching control panel with endpoints from configs/tool_registry.yaml (profile=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlocal-colab\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m control_panel = create_control_panel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/sparkle_motion/notebooks/control_panel.py:57\u001b[39m\n\u001b[32m     54\u001b[39m widgets = _load_widgets_module()\n\u001b[32m     55\u001b[39m display = _load_display()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msparkle_motion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool_registry\n\u001b[32m     59\u001b[39m DEFAULT_HTTP_TIMEOUT_S = \u001b[32m30.0\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEndpointResolutionError\u001b[39;00m(\u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sparkle_motion'"
     ]
    }
   ],
   "source": [
    "# Quickstart cell: import and display the ipywidgets control panel\n",
    "from notebooks.control_panel import create_control_panel\n",
    "\n",
    "print(\"Launching control panel with endpoints from configs/tool_registry.yaml (profile='local-colab').\")\n",
    "control_panel = create_control_panel()\n",
    "control_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d24cce",
   "metadata": {},
   "source": [
    "## Notebook control panel prototype (advanced)\n",
    "Need to override the timeout, point at a different profile, or inspect the underlying widgets? Use the cell below to instantiate `ControlPanel` manually. It shows how to swap endpoint profiles, tweak HTTP timeouts, and still reuse the global `control_panel` handle for downstream helpers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced control panel prototype: customize endpoints/timeouts\n",
    "from notebooks.control_panel import ControlPanel, PanelEndpoints\n",
    "\n",
    "CUSTOM_PROFILE = \"local-colab\"  # change to another profile defined in configs/tool_registry.yaml\n",
    "CUSTOM_TIMEOUT_S = 45.0\n",
    "\n",
    "print(f\"Building ControlPanel(profile={CUSTOM_PROFILE!r}, timeout={CUSTOM_TIMEOUT_S}s)...\")\n",
    "custom_endpoints = PanelEndpoints.from_registry(profile=CUSTOM_PROFILE)\n",
    "advanced_control_panel = ControlPanel(endpoints=custom_endpoints, http_timeout_s=CUSTOM_TIMEOUT_S)\n",
    "\n",
    "# Keep downstream helpers working by updating the shared reference.\n",
    "control_panel = advanced_control_panel\n",
    "advanced_control_panel.container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab0c57",
   "metadata": {},
   "source": [
    "## Final deliverable preview & download\n",
    "Use this helper after a production run completes. It fetches the `video_final` artifact from `qa_publish`, embeds it inline, surfaces the QA badge, and offers a Google Colab download when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Final deliverable helper (qa_publish)\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import httpx\n",
    "from IPython.display import HTML, Video, display\n",
    "\n",
    "PRODUCTION_AGENT_BASE = os.environ.get(\"PRODUCTION_AGENT_BASE\", \"http://127.0.0.1:8200\")\n",
    "QA_PUBLISH_STAGE = \"qa_publish\"\n",
    "DOWNLOAD_DIR = Path(os.environ.get(\"FINAL_VIDEO_DIR\", \"/content/final_videos\"))\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "colab_files = None\n",
    "_colab_spec = importlib.util.find_spec(\"google.colab.files\")\n",
    "if _colab_spec:\n",
    "    colab_files = importlib.import_module(\"google.colab.files\")\n",
    "\n",
    "\n",
    "def _current_run_id() -> str:\n",
    "    if \"control_panel\" in globals():\n",
    "        cp = globals()[\"control_panel\"]\n",
    "        run_value = getattr(getattr(cp, \"run_id_input\", None), \"value\", \"\")\n",
    "        if run_value and run_value.strip():\n",
    "            return run_value.strip()\n",
    "        state = getattr(cp, \"state\", None)\n",
    "        if state and getattr(state, \"last_run_request_id\", None):\n",
    "            return state.last_run_request_id\n",
    "    return os.environ.get(\"RUN_ID\", \"\").strip()\n",
    "\n",
    "\n",
    "RUN_ID = _current_run_id()\n",
    "if not RUN_ID:\n",
    "    raise RuntimeError(\n",
    "        \"Set RUN_ID (or populate control_panel.run_id_input) before running the final deliverable helper.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def _summarize_stage(stage_section: Dict[str, Any]) -> Dict[str, Optional[Dict[str, Any]]]:\n",
    "    preview = stage_section.get(\"preview\") or {}\n",
    "    media_summary = stage_section.get(\"media_summary\") or {}\n",
    "    qa_summary = stage_section.get(\"qa_summary\") or {}\n",
    "    preview_video = preview.get(\"video\")\n",
    "    log_lines = [\n",
    "        f\"qa_publish emitted {stage_section.get('count', 0)} artifact(s)\",\n",
    "        f\"artifact_types: {stage_section.get('artifact_types') or []}\",\n",
    "        f\"media_types: {stage_section.get('media_types') or []}\",\n",
    "    ]\n",
    "    if preview_video:\n",
    "        location_hint = preview_video.get(\"local_path\") or preview_video.get(\"download_url\") or preview_video.get(\"artifact_uri\")\n",
    "        log_lines.append(\n",
    "            \"video preview => \"\n",
    "            f\"playback_ready={preview_video.get('playback_ready')} \"\n",
    "            f\"qa_passed={preview_video.get('qa_passed')} \"\n",
    "            f\"source={location_hint}\",\n",
    "        )\n",
    "    else:\n",
    "        log_lines.append(\"video preview => unavailable\")\n",
    "    video_summary = media_summary.get(\"video\")\n",
    "    if video_summary:\n",
    "        log_lines.append(\n",
    "            \"video summary => \"\n",
    "            f\"count={video_summary.get('count', 0)} duration_s={video_summary.get('total_duration_s', 0.0):.2f} \"\n",
    "            f\"playback_ready={video_summary.get('playback_ready')}\",\n",
    "        )\n",
    "    if qa_summary:\n",
    "        log_lines.append(f\"qa summary => {qa_summary}\")\n",
    "    print(\"\\n\".join(log_lines))\n",
    "    return {\n",
    "        \"preview\": preview_video,\n",
    "        \"media_summary\": media_summary,\n",
    "        \"qa_summary\": qa_summary,\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_video_final_entry(run_id: str) -> Dict[str, Any]:\n",
    "    with httpx.Client(timeout=30.0) as client:\n",
    "        resp = client.get(\n",
    "            f\"{PRODUCTION_AGENT_BASE}/artifacts\",\n",
    "            params={\"run_id\": run_id, \"stage\": QA_PUBLISH_STAGE},\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        payload = resp.json()\n",
    "\n",
    "    stage_sections = payload.get(\"stages\") or []\n",
    "    if stage_sections:\n",
    "        stage_section = stage_sections[0]  # stage filter ensures only one section\n",
    "        summaries = _summarize_stage(stage_section)\n",
    "        fetch_video_final_entry._latest_preview = summaries[\"preview\"]  # type: ignore[attr-defined]\n",
    "        fetch_video_final_entry._latest_media_summary = summaries[\"media_summary\"]  # type: ignore[attr-defined]\n",
    "        fetch_video_final_entry._latest_qa_summary = summaries[\"qa_summary\"]  # type: ignore[attr-defined]\n",
    "        candidate_entries = stage_section.get(\"artifacts\") or []\n",
    "    else:\n",
    "        print(\n",
    "            \"Warning: /artifacts response missing 'stages' metadata; falling back to flattened artifacts list.\",\n",
    "        )\n",
    "        fetch_video_final_entry._latest_preview = None  # type: ignore[attr-defined]\n",
    "        fetch_video_final_entry._latest_media_summary = None  # type: ignore[attr-defined]\n",
    "        fetch_video_final_entry._latest_qa_summary = None  # type: ignore[attr-defined]\n",
    "        candidate_entries = payload.get(\"artifacts\") or []\n",
    "    for entry in candidate_entries:\n",
    "        if entry.get(\"artifact_type\") == \"video_final\":\n",
    "            return entry\n",
    "    raise RuntimeError(\n",
    "        \"No video_final artifact found. Ensure qa_publish succeeded or resume production_agent with resume_from='qa_publish'.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def ensure_local_video(entry: Dict[str, Any], run_id: str) -> Path:\n",
    "    local_path = entry.get(\"local_path\")\n",
    "    if local_path:\n",
    "        candidate = Path(local_path).expanduser()\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    target = DOWNLOAD_DIR / f\"{run_id}_video_final.mp4\"\n",
    "    download_url = entry.get(\"download_url\")\n",
    "    if download_url:\n",
    "        with httpx.Client(timeout=None) as client:\n",
    "            with client.stream(\"GET\", download_url) as resp:\n",
    "                resp.raise_for_status()\n",
    "                with target.open(\"wb\") as handle:\n",
    "                    for chunk in resp.iter_bytes():\n",
    "                        handle.write(chunk)\n",
    "        return target\n",
    "    artifact_uri = entry.get(\"artifact_uri\")\n",
    "    if artifact_uri:\n",
    "        result = subprocess.run(\n",
    "            [\"adk\", \"artifacts\", \"download\", artifact_uri, str(target)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False,\n",
    "        )\n",
    "        if result.returncode == 0 and target.exists():\n",
    "            return target\n",
    "        print(\"ADK artifact download failed:\")\n",
    "        print(result.stderr or result.stdout)\n",
    "    raise RuntimeError(\n",
    "        \"Unable to download the final video locally. Provide download_url or local_path in the artifacts manifest.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def render_qa_badge(entry: Dict[str, Any]) -> HTML:\n",
    "    qa_skipped = entry.get(\"qa_skipped\")\n",
    "    if qa_skipped is None:\n",
    "        qa_skipped = (entry.get(\"metadata\") or {}).get(\"qa_skipped\")\n",
    "    color = \"#d9534f\" if qa_skipped else \"#5cb85c\"\n",
    "    label = \"QA SKIPPED — manual review required\" if qa_skipped else \"QA PASSED\"\n",
    "    html = f\"\"\"\n",
    "    <div style=\\\"padding:6px 10px;background:{color};color:white;display:inline-block;border-radius:6px;font-weight:bold;\\\">\n",
    "        {label}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return HTML(html)\n",
    "\n",
    "\n",
    "def render_preview_video(preview_entry: Optional[Dict[str, Any]]) -> None:\n",
    "    if not preview_entry:\n",
    "        print(\"No preview clip available from /artifacts preview metadata.\")\n",
    "        return\n",
    "    local_path = preview_entry.get(\"local_path\")\n",
    "    if local_path and Path(local_path).exists():\n",
    "        display(HTML(\"<strong>Preview clip</strong>\"))\n",
    "        display(Video(filename=local_path, embed=True, width=480, height=270))\n",
    "        return\n",
    "    download_url = preview_entry.get(\"download_url\")\n",
    "    if download_url:\n",
    "        print(f\"Preview available remotely (download_url={download_url}).\")\n",
    "    else:\n",
    "        print(\"Preview metadata present but no local path or download URL; see artifact_uri for details.\")\n",
    "\n",
    "\n",
    "final_entry = fetch_video_final_entry(RUN_ID)\n",
    "preview_entry = getattr(fetch_video_final_entry, \"_latest_preview\", None)\n",
    "display(render_qa_badge(final_entry))\n",
    "render_preview_video(preview_entry)\n",
    "video_path = ensure_local_video(final_entry, RUN_ID)\n",
    "\n",
    "info_html = f\"\"\"\n",
    "<p><strong>Artifact URI:</strong> {final_entry.get('artifact_uri', 'n/a')}</p>\n",
    "<p><strong>Local path:</strong> {video_path}</p>\n",
    "\"\"\"\n",
    "display(HTML(info_html))\n",
    "display(Video(filename=str(video_path), embed=True, width=640, height=360))\n",
    "\n",
    "if colab_files is not None:\n",
    "    colab_files.download(str(video_path))\n",
    "else:\n",
    "    print(\"Download helper available only inside Google Colab. Share the path above manually if running elsewhere.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4b638",
   "metadata": {},
   "source": [
    "## Artifacts viewer\n",
    "Use this helper to inspect `/artifacts` responses without leaving the notebook. It shares the `control_panel` run metadata when available, lets you scope by stage (e.g., `qa_publish`), and can poll automatically so new artifacts appear as production advances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4c: Artifacts viewer helper\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import httpx\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "PRODUCTION_AGENT_BASE = os.environ.get(\"PRODUCTION_AGENT_BASE\", \"http://127.0.0.1:8200\")\n",
    "ARTIFACTS_ENDPOINT = f\"{PRODUCTION_AGENT_BASE}/artifacts\"\n",
    "\n",
    "if \"artifact_viewer_state\" in globals():\n",
    "    existing_task = globals()[\"artifact_viewer_state\"].get(\"task\")\n",
    "    if existing_task and not existing_task.done():\n",
    "        existing_task.cancel()\n",
    "\n",
    "artifact_viewer_state = {\"task\": None}\n",
    "\n",
    "\n",
    "def _artifact_viewer_run_id() -> str:\n",
    "    if \"control_panel\" in globals():\n",
    "        cp = globals()[\"control_panel\"]\n",
    "        run_widget = getattr(cp, \"run_id_input\", None)\n",
    "        candidate = getattr(run_widget, \"value\", \"\")\n",
    "        if candidate and candidate.strip():\n",
    "            return candidate.strip()\n",
    "        state = getattr(cp, \"state\", None)\n",
    "        if state and getattr(state, \"last_run_request_id\", None):\n",
    "            return state.last_run_request_id\n",
    "    return os.environ.get(\"RUN_ID\", \"\").strip()\n",
    "\n",
    "\n",
    "def _format_status_html(message: str, *, ok: bool) -> str:\n",
    "    color = \"#3c763d\" if ok else \"#d9534f\"\n",
    "    return f\"<span style='color:{color}; font-size:0.9em;'>{message}</span>\"\n",
    "\n",
    "\n",
    "def _iter_artifacts(payload: Dict[str, Any]):\n",
    "    stages = payload.get(\"stages\") or []\n",
    "    for stage in stages:\n",
    "        for artifact in stage.get(\"artifacts\") or []:\n",
    "            yield artifact\n",
    "    for artifact in payload.get(\"artifacts\") or []:\n",
    "        yield artifact\n",
    "\n",
    "\n",
    "def _locate_video_final(payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    for artifact in _iter_artifacts(payload):\n",
    "        if artifact.get(\"artifact_type\") == \"video_final\":\n",
    "            return artifact\n",
    "    return None\n",
    "\n",
    "\n",
    "def _render_artifacts(payload: Dict[str, Any]) -> None:\n",
    "    artifacts = list(_iter_artifacts(payload))\n",
    "    video_final = _locate_video_final(payload)\n",
    "    with artifacts_output:\n",
    "        artifacts_output.clear_output()\n",
    "        print(f\"Artifacts returned: {len(artifacts)}\")\n",
    "        if video_final:\n",
    "            print(\"\\nvideo_final summary:\")\n",
    "            print(json.dumps(video_final, indent=2, ensure_ascii=False))\n",
    "        print(\"\\nFull payload:\\n\")\n",
    "        print(json.dumps(payload, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "def _fetch_artifacts_sync(run_id: str, stage: str) -> Dict[str, Any]:\n",
    "    params = {\"run_id\": run_id}\n",
    "    if stage:\n",
    "        params[\"stage\"] = stage\n",
    "    with httpx.Client(timeout=30.0) as client:\n",
    "        resp = client.get(ARTIFACTS_ENDPOINT, params=params)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        if not isinstance(data, dict):\n",
    "            raise RuntimeError(\"Unexpected artifacts response payload\")\n",
    "        return data\n",
    "\n",
    "\n",
    "async def _fetch_artifacts_async(client: httpx.AsyncClient, run_id: str, stage: str) -> Dict[str, Any]:\n",
    "    params = {\"run_id\": run_id}\n",
    "    if stage:\n",
    "        params[\"stage\"] = stage\n",
    "    resp = await client.get(ARTIFACTS_ENDPOINT, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if not isinstance(data, dict):\n",
    "        raise RuntimeError(\"Unexpected artifacts response payload\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def _stop_artifact_poll(*, from_toggle: bool = False) -> None:\n",
    "    task = artifact_viewer_state.get(\"task\")\n",
    "    if task and not task.done():\n",
    "        task.cancel()\n",
    "    artifact_viewer_state[\"task\"] = None\n",
    "    if not from_toggle:\n",
    "        auto_refresh_toggle.value = False\n",
    "\n",
    "\n",
    "def _handle_manual_refresh(_: Any) -> None:\n",
    "    run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "    if not run_id:\n",
    "        status_label.value = _format_status_html(\"Set a Run ID to fetch artifacts.\", ok=False)\n",
    "        with artifacts_output:\n",
    "            artifacts_output.clear_output()\n",
    "            print(\"Provide a Run ID before refreshing artifacts.\")\n",
    "        return\n",
    "    try:\n",
    "        payload = _fetch_artifacts_sync(run_id, stage_input.value.strip())\n",
    "    except httpx.HTTPError as exc:\n",
    "        status_label.value = _format_status_html(f\"Fetch failed: {exc}\", ok=False)\n",
    "        return\n",
    "    except Exception as exc:\n",
    "        status_label.value = _format_status_html(f\"Unexpected error: {exc}\", ok=False)\n",
    "        return\n",
    "    _render_artifacts(payload)\n",
    "    status_label.value = _format_status_html(\"Artifacts refreshed.\", ok=True)\n",
    "\n",
    "\n",
    "def _handle_auto_toggle(change: Dict[str, Any]) -> None:\n",
    "    if change.get(\"new\"):\n",
    "        _start_artifact_poll()\n",
    "    else:\n",
    "        _stop_artifact_poll(from_toggle=True)\n",
    "\n",
    "\n",
    "def _start_artifact_poll() -> None:\n",
    "    run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "    if not run_id:\n",
    "        status_label.value = _format_status_html(\"Set a Run ID before enabling auto-refresh.\", ok=False)\n",
    "        auto_refresh_toggle.value = False\n",
    "        return\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    async def _poll() -> None:\n",
    "        try:\n",
    "            async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "                while auto_refresh_toggle.value:\n",
    "                    stage = stage_input.value.strip()\n",
    "                    active_run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "                    if not active_run_id:\n",
    "                        status_label.value = _format_status_html(\"Run ID cleared; stopping auto-refresh.\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    try:\n",
    "                        payload = await _fetch_artifacts_async(client, active_run_id, stage)\n",
    "                    except httpx.HTTPError as exc:\n",
    "                        status_label.value = _format_status_html(f\"Auto-refresh failed: {exc}\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    except Exception as exc:\n",
    "                        status_label.value = _format_status_html(f\"Error: {exc}\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    _render_artifacts(payload)\n",
    "                    status_label.value = _format_status_html(\"Auto-refresh OK.\", ok=True)\n",
    "                    interval = max(2.0, float(interval_input.value or 4.0))\n",
    "                    await asyncio.sleep(interval)\n",
    "        except asyncio.CancelledError:\n",
    "            status_label.value = _format_status_html(\"Auto-refresh stopped.\", ok=True)\n",
    "\n",
    "    _stop_artifact_poll(from_toggle=True)\n",
    "    artifact_viewer_state[\"task\"] = loop.create_task(_poll())\n",
    "\n",
    "\n",
    "run_id_input = widgets.Text(\n",
    "    value=_artifact_viewer_run_id(),\n",
    "    description=\"Run ID\",\n",
    "    placeholder=\"production run id\",\n",
    "    layout=widgets.Layout(width=\"50%\"),\n",
    ")\n",
    "stage_input = widgets.Text(\n",
    "    description=\"Stage\",\n",
    "    placeholder=\"Optional stage (e.g., qa_publish)\",\n",
    "    layout=widgets.Layout(width=\"45%\"),\n",
    ")\n",
    "refresh_button = widgets.Button(description=\"Refresh\", icon=\"refresh\")\n",
    "auto_refresh_toggle = widgets.ToggleButton(description=\"Auto-refresh\", icon=\"repeat\", value=False)\n",
    "interval_input = widgets.BoundedFloatText(value=4.0, min=2.0, max=60.0, step=1.0, description=\"Interval (s)\")\n",
    "status_label = widgets.HTML(value=_format_status_html(\"Idle\", ok=True))\n",
    "artifacts_output = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", min_height=\"160px\", max_height=\"360px\", overflow=\"auto\"))\n",
    "\n",
    "refresh_button.on_click(_handle_manual_refresh)\n",
    "auto_refresh_toggle.observe(_handle_auto_toggle, names=\"value\")\n",
    "\n",
    "controls_row_1 = widgets.HBox([run_id_input, stage_input])\n",
    "controls_row_2 = widgets.HBox([refresh_button, auto_refresh_toggle, interval_input, status_label])\n",
    "artifacts_viewer_panel = widgets.VBox([controls_row_1, controls_row_2, artifacts_output])\n",
    "\n",
    "display(artifacts_viewer_panel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de9b1a",
   "metadata": {},
   "source": [
    "## Optional: run a stub orchestration smoke test\n",
    "This cell runs the Python runner in simulation mode (fallback adapters) so you can confirm Drive folders are writable before enabling real models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Optional orchestrator smoke run (uses fallback adapters)\n",
    "import importlib.util\n",
    "from sparkle_motion.orchestrator import Runner\n",
    "in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "if in_colab:\n",
    "    runs_root = Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \"runs\"\n",
    "else:\n",
    "    runs_root = REPO_ROOT / \"runs\"\n",
    "runs_root.mkdir(parents=True, exist_ok=True)\n",
    "movie_plan = {\n",
    "    \"title\": \"Colab Smoke\",\n",
    "    \"shots\": [\n",
    "        {\n",
    "            \"id\": \"shot_001\",\n",
    "            \"visual_description\": \"Test scene\",\n",
    "            \"duration_sec\": 2.0,\n",
    "            \"dialogue\": [{\"character\": \"narrator\", \"text\": \"Hello from Colab\"}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "runner = Runner(runs_root=str(runs_root))\n",
    "asset_refs = runner.run(movie_plan=movie_plan, run_id=\"colab_smoke\", resume=True)\n",
    "print(\"Smoke run complete. Final asset refs keys:\", asset_refs.keys())\n",
    "print(\"Runs directory:\", runs_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkle_motion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
