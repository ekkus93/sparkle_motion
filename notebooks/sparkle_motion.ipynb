{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eda5d3",
   "metadata": {},
   "source": [
    "# sparkle_motion — Colab / Drive setup\n",
    "This notebook contains the recommended Colab setup steps and a small smoke-test harness for running the orchestrator in a GPU environment.\n",
    "- Use the cells below to mount Google Drive (Colab only).\n",
    "- Use the installation cell to install the ML stack from `requirements-ml.txt` (optional; heavy).\n",
    "- The smoke-test cell is a safe stub that checks imports and shows how to run the orchestrator in simulation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c497420",
   "metadata": {},
   "source": [
    "## Notes and expectations\n",
    "- This notebook is intended for Google Colab (A100) runs. If you are running locally, skip the Drive mount and run the commands in a terminal.\n",
    "- Before installing the heavy ML dependencies, ensure you have sufficient disk and GPU (Colab or a VM). The requirements are listed in `requirements-ml.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56db335",
   "metadata": {},
   "source": [
    "## Configure workspace inputs\n",
    "Set these before running the helper so it knows where to create directories and which model snapshots to pull. Provide one or more repo IDs via `HF_MODELS`; set `DRY_RUN = True` or leave the list empty to skip downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2587a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured workspace 'SparkleMotion' (repo root: /home/phil/work/sparkle_motion/notebooks)\n",
      "Models to manage: ['stabilityai/stable-diffusion-xl-base-1.0']\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Workspace configuration (edit these as needed)\n",
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE_NAME = \"SparkleMotion\"          # Folder created under MyDrive/\n",
    "HF_MODELS = [\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "]\n",
    "DRY_RUN = False                              # True = skip download/smoke actions\n",
    "MOUNT_POINT = \"/content/drive\"             # Default Colab mount\n",
    "REPO_ROOT = Path.cwd()                       # Assumes notebook is opened from repo root\n",
    "\n",
    "print(f\"Configured workspace '{WORKSPACE_NAME}' (repo root: {REPO_ROOT})\")\n",
    "print(f\"Models to manage: {HF_MODELS or '[none specified]'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e641fa1",
   "metadata": {},
   "source": [
    "## Load secrets from `.env`\n",
    "Run the next cell once the bootstrap script has created a `.env` file (either in the\n",
    "repo root, `/content`, or your Drive workspace). It installs `python-dotenv` if\n",
    "necessary and loads the variables into the current kernel so the ADK clients can\n",
    "reuse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb81eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0a: Load secrets from .env using python-dotenv\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _ensure_python_dotenv_installed() -> None:\n",
    "    if importlib.util.find_spec(\"dotenv\") is None:\n",
    "        print(\"Installing python-dotenv...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-dotenv\"])\n",
    "\n",
    "\n",
    "_ensure_python_dotenv_installed()\n",
    "from dotenv import load_dotenv  # type: ignore  # imported after ensuring package\n",
    "\n",
    "candidate_paths = [\n",
    "    REPO_ROOT / \".env.local\",\n",
    "    REPO_ROOT / \".env\",\n",
    "    Path(\"/content/.env\"),\n",
    "    Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \".env\",\n",
    "]\n",
    "\n",
    "env_path = next((path for path in candidate_paths if path.exists()), None)\n",
    "if env_path is None:\n",
    "    print(\n",
    "        \"No .env file found. Run scripts/bootstrap_adk_projects.sh --profile local-colab \"\n",
    "        \"and re-run this cell once the file exists.\"\n",
    "    )\n",
    "else:\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"Loaded environment variables from {env_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Mount Google Drive (Colab-only)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "if not in_colab:\n",
    "    print(\"Not running inside Google Colab; skipping Drive mount.\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "\n",
    "    mount_target = Path(MOUNT_POINT)\n",
    "    mount_target.mkdir(parents=True, exist_ok=True)\n",
    "    if os.path.ismount(mount_target):\n",
    "        print(f\"Google Drive already mounted at {mount_target}.\")\n",
    "    else:\n",
    "        print(f\"Mounting Google Drive at {mount_target}...\")\n",
    "        drive.mount(str(mount_target), force_remount=False)\n",
    "\n",
    "    workspace_root = mount_target / \"MyDrive\" / WORKSPACE_NAME\n",
    "    workspace_root.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Workspace directory ready at {workspace_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35371e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install ML dependencies from requirements-ml.txt (Colab / heavy)\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "def sh(cmd):\n",
    "    print('Running:', cmd)\n",
    "    return subprocess.check_call(cmd, shell=True)\n",
    "\n",
    "\n",
    "if importlib.util.find_spec('google.colab'):\n",
    "    print('Detected Colab.\\n')\n",
    "    print('If you need a CUDA-optimized torch wheel, install it first as recommended in the repo notebook.\\n')\n",
    "    # The repository contains requirements-ml.txt at the repo root.\n",
    "    # If you placed the repository under Drive, adjust the path accordingly (e.g. /content/drive/MyDrive/sparkle_motion/requirements-ml.txt).\n",
    "    req_path = 'requirements-ml.txt'\n",
    "    try:\n",
    "        sh(f'pip install -r \"{req_path}\"')\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        print('pip install failed:', exc)\n",
    "else:\n",
    "    print('Not running in Colab — to install locally run:\\n    pip install -r requirements-ml.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a038a",
   "metadata": {},
   "source": [
    "## Colab preflight helper\n",
    "Use this helper right after the install cell to confirm ADC auth, env vars, Drive mount, and `/ready` endpoints before touching the control panel. The helper wraps `python -m sparkle_motion.notebook_preflight` so you can rerun it any time during the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2a: Run the consolidated Colab preflight checks\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from sparkle_motion.notebook_preflight import format_report, run_preflight_checks\n",
    "\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "preflight_results = run_preflight_checks(\n",
    "    requirements_path=REPO_ROOT / \"requirements-ml.txt\",\n",
    "    mount_point=Path(MOUNT_POINT),\n",
    "    workspace_dir=Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME,\n",
    "    ready_endpoints=(\n",
    "        \"http://localhost:8101/ready\",\n",
    "        \"http://localhost:8200/ready\",\n",
    "    ),\n",
    "    pip_mode=\"install\",\n",
    "    require_drive=IN_COLAB,\n",
    "    skip_gpu_checks=not IN_COLAB,\n",
    " )\n",
    "\n",
    "print(format_report(preflight_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b720abb",
   "metadata": {},
   "source": [
    "## Prepare Drive workspace and download models\n",
    "Use the helper script added to the repo (`scripts/colab_drive_setup.py`) to create Drive folders, optionally download Hugging Face weights, and write a smoke artifact in `outputs/colab_smoke.json`.\n",
    "- When running locally (outside Colab), pass `--local-root /path/to/workspace` so the helper skips the Drive mount and uses your filesystem directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777417cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Force-set REPO_ROOT to /home/phil/work/sparkle_motion\n"
     ]
    }
   ],
   "source": [
    "# Run once before Cell 4\n",
    "REPO_ROOT = Path(\"/home/phil/work/sparkle_motion\")\n",
    "print(\"Force-set REPO_ROOT to\", REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d0ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running inside Google Colab. Run the helper manually from a terminal:\n",
      "  PYTHONPATH=\"/home/phil/work/sparkle_motion/src\" python /home/phil/work/sparkle_motion/scripts/colab_drive_setup.py SparkleMotion --local-root /home/phil/work/sparkle_motion/colab_drive_workspace --model stabilityai/stable-diffusion-xl-base-1.0\n",
      "Adjust --local-root to a writable directory if you prefer a different location.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Invoke Drive helper (creates folders, optional download)\n",
    "import importlib.util\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "helper_path = REPO_ROOT / \"scripts\" / \"colab_drive_setup.py\"\n",
    "if not helper_path.exists():\n",
    "    print(f\"Helper script not found at {helper_path}. Ensure you're running the notebook from the repo root.\")\n",
    "else:\n",
    "    in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "    if not in_colab:\n",
    "        print(\"Not running inside Google Colab. Run the helper manually from a terminal:\")\n",
    "        local_root = (REPO_ROOT / \"colab_drive_workspace\").resolve()\n",
    "        cmd_parts = [\n",
    "            f\"PYTHONPATH=\\\"{REPO_ROOT / 'src'}\\\"\",\n",
    "            \"python\",\n",
    "            str(helper_path),\n",
    "            WORKSPACE_NAME,\n",
    "            \"--local-root\",\n",
    "            str(local_root),\n",
    "        ]\n",
    "        for repo_id in HF_MODELS:\n",
    "            cmd_parts.extend([\"--model\", repo_id])\n",
    "        if DRY_RUN:\n",
    "            cmd_parts.append(\"--dry-run\")\n",
    "        print(\"  \" + \" \".join(cmd_parts))\n",
    "        print(\"Adjust --local-root to a writable directory if you prefer a different location.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            str(helper_path),\n",
    "            WORKSPACE_NAME,\n",
    "            \"--mount-point\",\n",
    "            str(MOUNT_POINT),\n",
    "        ]\n",
    "        for repo_id in HF_MODELS:\n",
    "            cmd.extend([\"--model\", repo_id])\n",
    "        if DRY_RUN:\n",
    "            cmd.append(\"--dry-run\")\n",
    "        print(\"Running helper:\", \" \".join(cmd))\n",
    "        subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4b: Inspect smoke artifact with per-model status\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "smoke_path = Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \"outputs\" / \"colab_smoke.json\"\n",
    "if smoke_path.exists():\n",
    "    data = json.loads(smoke_path.read_text(encoding=\"utf-8\"))\n",
    "    status = \"OK\" if data.get(\"ok\") else \"FAILED\"\n",
    "    print(f\"Smoke status: {status}\")\n",
    "    for model in data.get(\"models\", []):\n",
    "        sample = model.get(\"sample_file\") or \"n/a\"\n",
    "        print(\n",
    "            f\"- {model['repo_id']}: {model['status']} \"\n",
    "            f\"({model.get('files_present', 0)} files, sample={sample})\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"No smoke artifact found at {smoke_path}. Run the helper once to generate it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c97200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Smoke-test stub for the orchestrator (safe, non-destructive)\n",
    "# This cell attempts to import the orchestrator package and reports what is available.\n",
    "try:\n",
    "    import sparkle_motion.orchestrator as orchestrator_mod\n",
    "    print('Imported sparkle_motion.orchestrator ->', orchestrator_mod)\n",
    "    if hasattr(orchestrator_mod, 'Runner'):\n",
    "        print('Runner class is available. You can instantiate it for a simulation run.')\n",
    "        print('Example (local):')\n",
    "        print(\"  from sparkle_motion.orchestrator import Runner\")\n",
    "        print(\"  r = Runner(run_dir='runs')\")\n",
    "        print(\"  # then use r.run(...) or similar per your orchestrator API\")\n",
    "    else:\n",
    "        print('Runner class not found — inspect src/sparkle_motion/orchestrator.py for usage.')\n",
    "except Exception as e:\n",
    "    print('Could not import orchestrator module:', e)\n",
    "    print('If you want to run the orchestrator, ensure the package is on PYTHONPATH (e.g., pip install -e .) or run via the repository root.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08966a60",
   "metadata": {},
   "source": [
    "## Quickstart: Launch the control panel\n",
    "Run this cell after the FunctionTools are live (script_agent + production_agent listening on localhost). It imports `create_control_panel`, instantiates the widgets with the `local-colab` profile, and stores the panel in `control_panel` so later helpers (status polling, final deliverable preview) can reuse the same run metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4da3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "REPO_ROOT = Path(\"/home/phil/work/sparkle_motion\")  # or Path.cwd() if already in repo\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.append(str(REPO_ROOT))\n",
    "SRC_PATH = REPO_ROOT / \"src\"\n",
    "if str(SRC_PATH) not in sys.path:\n",
    "    sys.path.append(str(SRC_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1289a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching control panel with endpoints from configs/tool_registry.yaml (profile='local-colab').\n",
      "[control_panel] Logging events to /home/phil/work/sparkle_motion/artifacts/logs/control_panel_20251201_073904.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8505ec4f1d164c87be9507819e69ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Text(value='', description='Title', placeholder='Short film title'), Textarea(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<notebooks.control_panel.ControlPanel at 0x7b7c8f1f2490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickstart cell: import and display the ipywidgets control panel\n",
    "from notebooks.control_panel import create_control_panel\n",
    "\n",
    "print(\"Launching control panel with endpoints from configs/tool_registry.yaml (profile='local-colab').\")\n",
    "control_panel = create_control_panel()\n",
    "control_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "824ad861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control panel run_id set to run_a12af6a94ab5\n"
     ]
    }
   ],
   "source": [
    "# Helper: set run_id for artifacts viewing/tests\n",
    "TARGET_RUN_ID = \"run_a12af6a94ab5\"  # Latest local run with qa_publish artifacts\n",
    "if \"control_panel\" in globals():\n",
    "    if hasattr(control_panel, \"run_id_input\"):\n",
    "        control_panel.run_id_input.value = TARGET_RUN_ID\n",
    "    state = getattr(control_panel, \"state\", None)\n",
    "    if state is not None:\n",
    "        state.last_run_id = TARGET_RUN_ID\n",
    "    print(f\"Control panel run_id set to {TARGET_RUN_ID}\")\n",
    "else:\n",
    "    print(\"control_panel is not initialized; run the quickstart cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adccde6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production run_id: run_68de8afd3a69\n",
      "poll 0: status=succeeded steps=12\n",
      "Control panel updated with new run_id.\n"
     ]
    }
   ],
   "source": [
    "# Launch a fresh production run for notebook verification\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import httpx\n",
    "\n",
    "PLAN_PATH = Path(\"/home/phil/work/sparkle_motion/artifacts/Test_Film.json\")\n",
    "plan_payload_raw = json.loads(PLAN_PATH.read_text())\n",
    "plan_payload = plan_payload_raw.get(\"validated_plan\") or plan_payload_raw\n",
    "request_body = {\"mode\": \"run\", \"qa_mode\": \"full\", \"plan\": plan_payload}\n",
    "with httpx.Client(timeout=60.0) as client:\n",
    "    invoke_resp = client.post(f\"{PRODUCTION_AGENT_BASE}/invoke\", json=request_body)\n",
    "    if invoke_resp.status_code >= 400:\n",
    "        snippet = invoke_resp.text[:800]\n",
    "        print(\"Invoke failed (truncated):\", snippet)\n",
    "        invoke_resp.raise_for_status()\n",
    "    invoke_data = invoke_resp.json()\n",
    "run_id_new = invoke_data[\"run_id\"]\n",
    "print(\"Production run_id:\", run_id_new)\n",
    "\n",
    "def _poll_status(run_id: str, *, timeout_s: float = 40.0) -> None:\n",
    "    with httpx.Client(timeout=10.0) as client:\n",
    "        start = time.time()\n",
    "        attempt = 0\n",
    "        while time.time() - start < timeout_s:\n",
    "            status = client.get(f\"{PRODUCTION_AGENT_BASE}/status\", params={\"run_id\": run_id}).json()\n",
    "            print(\n",
    "                f\"poll {attempt}: status={status.get('status')} steps={len(status.get('steps', []))}\"\n",
    "            )\n",
    "            if status.get(\"status\") == \"succeeded\":\n",
    "                return\n",
    "            attempt += 1\n",
    "            time.sleep(0.5)\n",
    "        raise RuntimeError(\"Run did not complete within timeout\")\n",
    "\n",
    "_poll_status(run_id_new)\n",
    "if \"control_panel\" in globals():\n",
    "    if hasattr(control_panel, \"run_id_input\"):\n",
    "        control_panel.run_id_input.value = run_id_new\n",
    "    state = getattr(control_panel, \"state\", None)\n",
    "    if state is not None:\n",
    "        state.last_run_id = run_id_new\n",
    "print(\"Control panel updated with new run_id.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d24cce",
   "metadata": {},
   "source": [
    "## Notebook control panel prototype (advanced)\n",
    "Need to override the timeout, point at a different profile, or inspect the underlying widgets? Use the cell below to instantiate `ControlPanel` manually. It shows how to swap endpoint profiles, tweak HTTP timeouts, and still reuse the global `control_panel` handle for downstream helpers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced control panel prototype: customize endpoints/timeouts\n",
    "from notebooks.control_panel import ControlPanel, PanelEndpoints\n",
    "\n",
    "CUSTOM_PROFILE = \"local-colab\"  # change to another profile defined in configs/tool_registry.yaml\n",
    "CUSTOM_TIMEOUT_S = 45.0\n",
    "\n",
    "print(f\"Building ControlPanel(profile={CUSTOM_PROFILE!r}, timeout={CUSTOM_TIMEOUT_S}s)...\")\n",
    "custom_endpoints = PanelEndpoints.from_registry(profile=CUSTOM_PROFILE)\n",
    "advanced_control_panel = ControlPanel(endpoints=custom_endpoints, http_timeout_s=CUSTOM_TIMEOUT_S)\n",
    "\n",
    "# Keep downstream helpers working by updating the shared reference.\n",
    "control_panel = advanced_control_panel\n",
    "advanced_control_panel.container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab0c57",
   "metadata": {},
   "source": [
    "## Final deliverable preview & download\n",
    "Use this helper after a production run completes. It fetches the `video_final` artifact from `qa_publish`, embeds it inline, surfaces the QA badge, and offers a Google Colab download when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed4be777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_VIDEO_DIR set to /home/phil/work/sparkle_motion/artifacts/final_videos\n"
     ]
    }
   ],
   "source": [
    "# Optional: configure FINAL_VIDEO_DIR for local runs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path(\"/content\").exists():\n",
    "    local_final_dir = REPO_ROOT / \"artifacts\" / \"final_videos\"\n",
    "    local_final_dir.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ[\"FINAL_VIDEO_DIR\"] = str(local_final_dir)\n",
    "    print(f\"FINAL_VIDEO_DIR set to {local_final_dir}\")\n",
    "else:\n",
    "    print(\"Detected /content, keep Colab default FINAL_VIDEO_DIR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c6576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa_publish emitted 2 artifact(s)\n",
      "artifact_types: ['video_final']\n",
      "media_types: ['video/mp4']\n",
      "video preview => playback_ready=True qa_passed=False source=/home/phil/work/sparkle_motion/artifacts/runs/run_a12af6a94ab5/test-film/final/test-film-video_final.mp4\n",
      "video summary => count=2 duration_s=18.00 playback_ready=True\n",
      "qa summary => {'total': 2, 'passed': 0, 'failed': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"padding:6px 10px;background:#5cb85c;color:white;display:inline-block;border-radius:6px;font-weight:bold;\">\n",
       "        QA PASSED\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Preview clip</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video controls  width=\"480\"  height=\"270\">\n",
       " <source src=\"data:video/mp4;base64,ewogICJwbGFuX2lkIjogInRlc3QtZmlsbSIsCiAgImdlbmVyYXRlZF9hdCI6ICIyMDI1LTEyLTAxVDA4OjI4OjQyLjA3ODQ5MFoiLAogICJub3RlIjogInFhX3B1Ymxpc2ggcGxhY2Vob2xkZXIiCn0=\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<p><strong>Artifact URI:</strong> file:///home/phil/work/sparkle_motion/artifacts/runs/run_a12af6a94ab5/video_final-1e7d86da41fa.mp4</p>\n",
       "<p><strong>Local path:</strong> /home/phil/work/sparkle_motion/artifacts/runs/run_a12af6a94ab5/test-film/final/test-film-video_final.mp4</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video controls  width=\"640\"  height=\"360\">\n",
       " <source src=\"data:video/mp4;base64,ewogICJwbGFuX2lkIjogInRlc3QtZmlsbSIsCiAgImdlbmVyYXRlZF9hdCI6ICIyMDI1LTEyLTAxVDA4OjI4OjQyLjA3ODQ5MFoiLAogICJub3RlIjogInFhX3B1Ymxpc2ggcGxhY2Vob2xkZXIiCn0=\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download helper available only inside Google Colab. Share the path above manually if running elsewhere.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Final deliverable helper (qa_publish)\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import httpx\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from notebooks import preview_helpers\n",
    "\n",
    "PRODUCTION_AGENT_BASE = os.environ.get(\"PRODUCTION_AGENT_BASE\", \"http://127.0.0.1:8200\")\n",
    "QA_PUBLISH_STAGE = \"qa_publish\"\n",
    "DOWNLOAD_DIR = Path(os.environ.get(\"FINAL_VIDEO_DIR\", \"/content/final_videos\"))\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "colab_files = None\n",
    "try:\n",
    "    _colab_spec = importlib.util.find_spec(\"google.colab.files\")\n",
    "except ModuleNotFoundError:\n",
    "    _colab_spec = None\n",
    "if _colab_spec:\n",
    "    colab_files = importlib.import_module(\"google.colab.files\")\n",
    "\n",
    "\n",
    "def _current_run_id() -> str:\n",
    "    if \"control_panel\" in globals():\n",
    "        cp = globals()[\"control_panel\"]\n",
    "        run_value = getattr(getattr(cp, \"run_id_input\", None), \"value\", \"\")\n",
    "        if run_value and run_value.strip():\n",
    "            return run_value.strip()\n",
    "        state = getattr(cp, \"state\", None)\n",
    "        if state and getattr(state, \"last_run_request_id\", None):\n",
    "            return state.last_run_request_id\n",
    "    return os.environ.get(\"RUN_ID\", \"\").strip()\n",
    "\n",
    "\n",
    "RUN_ID = _current_run_id()\n",
    "if not RUN_ID:\n",
    "    raise RuntimeError(\n",
    "        \"Set RUN_ID (or populate control_panel.run_id_input) before running the final deliverable helper.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def _fetch_stage_manifest(run_id: str) -> Dict[str, Any]:\n",
    "    stage_manifest = preview_helpers.fetch_stage_manifest(\n",
    "        base_url=PRODUCTION_AGENT_BASE,\n",
    "        run_id=run_id,\n",
    "        stage=QA_PUBLISH_STAGE,\n",
    "    )\n",
    "    print(preview_helpers.render_stage_summary(stage_manifest))\n",
    "    qa_summary = stage_manifest.get(\"qa_summary\")\n",
    "    if qa_summary:\n",
    "        print(f\"QA summary => {qa_summary}\")\n",
    "    return stage_manifest\n",
    "\n",
    "\n",
    "def _locate_video_final(stage_manifest: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    for entry in stage_manifest.get(\"artifacts\") or []:\n",
    "        if entry.get(\"artifact_type\") == \"video_final\":\n",
    "            return entry\n",
    "    raise RuntimeError(\n",
    "        \"No video_final artifact found. Ensure qa_publish succeeded or resume production_agent with resume_from='qa_publish'.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def ensure_local_video(entry: Dict[str, Any], run_id: str) -> Path:\n",
    "    local_path = entry.get(\"local_path\")\n",
    "    if local_path:\n",
    "        candidate = Path(local_path).expanduser()\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    target = DOWNLOAD_DIR / f\"{run_id}_video_final.mp4\"\n",
    "    download_url = entry.get(\"download_url\")\n",
    "    if download_url:\n",
    "        with httpx.Client(timeout=None) as client:\n",
    "            with client.stream(\"GET\", download_url) as resp:\n",
    "                resp.raise_for_status()\n",
    "                with target.open(\"wb\") as handle:\n",
    "                    for chunk in resp.iter_bytes():\n",
    "                        handle.write(chunk)\n",
    "        return target\n",
    "    artifact_uri = entry.get(\"artifact_uri\")\n",
    "    if artifact_uri:\n",
    "        result = subprocess.run(\n",
    "            [\"adk\", \"artifacts\", \"download\", artifact_uri, str(target)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False,\n",
    "        )\n",
    "        if result.returncode == 0 and target.exists():\n",
    "            return target\n",
    "        print(\"ADK artifact download failed:\")\n",
    "        print(result.stderr or result.stdout)\n",
    "    raise RuntimeError(\n",
    "        \"Unable to download the final video locally. Provide download_url or local_path in the artifacts manifest.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def render_qa_badge(entry: Dict[str, Any]) -> HTML:\n",
    "    qa_skipped = entry.get(\"qa_skipped\")\n",
    "    if qa_skipped is None:\n",
    "        qa_skipped = (entry.get(\"metadata\") or {}).get(\"qa_skipped\")\n",
    "    color = \"#d9534f\" if qa_skipped else \"#5cb85c\"\n",
    "    label = \"QA SKIPPED — manual review required\" if qa_skipped else \"QA PASSED\"\n",
    "    html = f\"\"\"\n",
    "    <div style=\\\"padding:6px 10px;background:{color};color:white;display:inline-block;border-radius:6px;font-weight:bold;\\\">\n",
    "        {label}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return HTML(html)\n",
    "\n",
    "\n",
    "def render_preview_video(preview_entry: Optional[Dict[str, Any]]) -> None:\n",
    "    if not preview_entry:\n",
    "        print(\"No preview clip available from /artifacts preview metadata.\")\n",
    "        return\n",
    "    local_path = preview_entry.get(\"local_path\")\n",
    "    if local_path and Path(local_path).exists():\n",
    "        display(HTML(\"<strong>Preview clip</strong>\"))\n",
    "        preview_widget = preview_helpers.create_video_widget(\n",
    "            {\"local_path\": local_path, \"artifact_type\": \"preview_clip\"},\n",
    "            width=480,\n",
    "        )\n",
    "        display(preview_widget)\n",
    "        return\n",
    "    download_url = preview_entry.get(\"download_url\")\n",
    "    if download_url:\n",
    "        print(f\"Preview available remotely (download_url={download_url}).\")\n",
    "    else:\n",
    "        print(\"Preview metadata present but no local path or download URL; see artifact_uri for details.\")\n",
    "\n",
    "\n",
    "stage_manifest = _fetch_stage_manifest(RUN_ID)\n",
    "preview_entry = (stage_manifest.get(\"preview\") or {}).get(\"video\")\n",
    "final_entry = _locate_video_final(stage_manifest)\n",
    "\n",
    "display(render_qa_badge(final_entry))\n",
    "render_preview_video(preview_entry)\n",
    "video_path = ensure_local_video(final_entry, RUN_ID)\n",
    "final_entry[\"local_path\"] = str(video_path)\n",
    "\n",
    "info_html = f\"\"\"\n",
    "<p><strong>Artifact URI:</strong> {final_entry.get('artifact_uri', 'n/a')}</p>\n",
    "<p><strong>Local path:</strong> {video_path}</p>\n",
    "\"\"\"\n",
    "display(HTML(info_html))\n",
    "\n",
    "display(preview_helpers.create_video_widget(final_entry, width=640))\n",
    "\n",
    "if colab_files is not None:\n",
    "    colab_files.download(str(video_path))\n",
    "else:\n",
    "    print(\"Download helper available only inside Google Colab. Share the path above manually if running elsewhere.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4b638",
   "metadata": {},
   "source": [
    "## Artifacts viewer\n",
    "Use this helper to inspect `/artifacts` responses without leaving the notebook. It shares the `control_panel` run metadata when available, lets you scope by stage (e.g., `qa_publish`), and can poll automatically so new artifacts appear as production advances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb6b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423618d5affc4401976636de4455b920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='run_a27a169010ad', description='Run ID', layout=Layout(width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4c: Artifacts viewer helper\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict\n",
    "\n",
    "import httpx\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from notebooks import preview_helpers\n",
    "\n",
    "PRODUCTION_AGENT_BASE = os.environ.get(\"PRODUCTION_AGENT_BASE\", \"http://127.0.0.1:8200\")\n",
    "ARTIFACTS_ENDPOINT = f\"{PRODUCTION_AGENT_BASE}/artifacts\"\n",
    "\n",
    "if \"artifact_viewer_state\" in globals():\n",
    "    existing_task = globals()[\"artifact_viewer_state\"].get(\"task\")\n",
    "    if existing_task and not existing_task.done():\n",
    "        existing_task.cancel()\n",
    "\n",
    "artifact_viewer_state = {\"task\": None}\n",
    "\n",
    "\n",
    "def _artifact_viewer_run_id() -> str:\n",
    "    if \"control_panel\" in globals():\n",
    "        cp = globals()[\"control_panel\"]\n",
    "        run_widget = getattr(cp, \"run_id_input\", None)\n",
    "        candidate = getattr(run_widget, \"value\", \"\")\n",
    "        if candidate and candidate.strip():\n",
    "            return candidate.strip()\n",
    "        state = getattr(cp, \"state\", None)\n",
    "        if state and getattr(state, \"last_run_request_id\", None):\n",
    "            return state.last_run_request_id\n",
    "    return os.environ.get(\"RUN_ID\", \"\").strip()\n",
    "\n",
    "\n",
    "def _format_status_html(message: str, *, ok: bool) -> str:\n",
    "    color = \"#3c763d\" if ok else \"#d9534f\"\n",
    "    return f\"<span style='color:{color}; font-size:0.9em;'>{message}</span>\"\n",
    "\n",
    "\n",
    "def _iter_artifacts(payload: Dict[str, Any]):\n",
    "    stages = payload.get(\"stages\") or []\n",
    "    for stage in stages:\n",
    "        for artifact in stage.get(\"artifacts\") or []:\n",
    "            yield artifact\n",
    "    for artifact in payload.get(\"artifacts\") or []:\n",
    "        yield artifact\n",
    "\n",
    "\n",
    "def _render_artifacts(payload: Dict[str, Any]) -> None:\n",
    "    artifacts = list(_iter_artifacts(payload))\n",
    "    stages = payload.get(\"stages\") or []\n",
    "    with artifacts_output:\n",
    "        artifacts_output.clear_output()\n",
    "        print(f\"Artifacts returned: {len(artifacts)}\")\n",
    "        if stages:\n",
    "            for stage in stages:\n",
    "                stage_label = stage.get(\"stage\") or stage.get(\"stage_id\") or \"stage\"\n",
    "                print(f\"\\nStage: {stage_label}\")\n",
    "                print(preview_helpers.render_stage_summary(stage))\n",
    "                previewable = [entry for entry in (stage.get(\"artifacts\") or []) if entry.get(\"local_path\")]\n",
    "                if previewable:\n",
    "                    preview_helpers.display_artifact_previews(\n",
    "                        {**stage, \"artifacts\": previewable},\n",
    "                        max_items=4,\n",
    "                        video_width=360,\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Local previews unavailable yet; see raw payload below.\")\n",
    "        else:\n",
    "            print(\"No stage sections returned; dumping raw payload.\")\n",
    "        print(\"\\nFull payload:\\n\")\n",
    "        print(json.dumps(payload, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "def _fetch_artifacts_sync(run_id: str, stage: str) -> Dict[str, Any]:\n",
    "    params = {\"run_id\": run_id}\n",
    "    if stage:\n",
    "        params[\"stage\"] = stage\n",
    "    with httpx.Client(timeout=30.0) as client:\n",
    "        resp = client.get(ARTIFACTS_ENDPOINT, params=params)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        if not isinstance(data, dict):\n",
    "            raise RuntimeError(\"Unexpected artifacts response payload\")\n",
    "        return data\n",
    "\n",
    "\n",
    "async def _fetch_artifacts_async(client: httpx.AsyncClient, run_id: str, stage: str) -> Dict[str, Any]:\n",
    "    params = {\"run_id\": run_id}\n",
    "    if stage:\n",
    "        params[\"stage\"] = stage\n",
    "    resp = await client.get(ARTIFACTS_ENDPOINT, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if not isinstance(data, dict):\n",
    "        raise RuntimeError(\"Unexpected artifacts response payload\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def _stop_artifact_poll(*, from_toggle: bool = False) -> None:\n",
    "    task = artifact_viewer_state.get(\"task\")\n",
    "    if task and not task.done():\n",
    "        task.cancel()\n",
    "    artifact_viewer_state[\"task\"] = None\n",
    "    if not from_toggle:\n",
    "        auto_refresh_toggle.value = False\n",
    "\n",
    "\n",
    "def _handle_manual_refresh(_: Any) -> None:\n",
    "    run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "    if not run_id:\n",
    "        status_label.value = _format_status_html(\"Set a Run ID to fetch artifacts.\", ok=False)\n",
    "        with artifacts_output:\n",
    "            artifacts_output.clear_output()\n",
    "            print(\"Provide a Run ID before refreshing artifacts.\")\n",
    "        return\n",
    "    try:\n",
    "        payload = _fetch_artifacts_sync(run_id, stage_input.value.strip())\n",
    "    except httpx.HTTPError as exc:\n",
    "        status_label.value = _format_status_html(f\"Fetch failed: {exc}\", ok=False)\n",
    "        return\n",
    "    except Exception as exc:\n",
    "        status_label.value = _format_status_html(f\"Unexpected error: {exc}\", ok=False)\n",
    "        return\n",
    "    _render_artifacts(payload)\n",
    "    status_label.value = _format_status_html(\"Artifacts refreshed.\", ok=True)\n",
    "\n",
    "\n",
    "def _handle_auto_toggle(change: Dict[str, Any]) -> None:\n",
    "    if change.get(\"new\"):\n",
    "        _start_artifact_poll()\n",
    "    else:\n",
    "        _stop_artifact_poll(from_toggle=True)\n",
    "\n",
    "\n",
    "def _start_artifact_poll() -> None:\n",
    "    run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "    if not run_id:\n",
    "        status_label.value = _format_status_html(\"Set a Run ID before enabling auto-refresh.\", ok=False)\n",
    "        auto_refresh_toggle.value = False\n",
    "        return\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    async def _poll() -> None:\n",
    "        try:\n",
    "            async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "                while auto_refresh_toggle.value:\n",
    "                    stage = stage_input.value.strip()\n",
    "                    active_run_id = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "                    if not active_run_id:\n",
    "                        status_label.value = _format_status_html(\"Run ID cleared; stopping auto-refresh.\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    try:\n",
    "                        payload = await _fetch_artifacts_async(client, active_run_id, stage)\n",
    "                    except httpx.HTTPError as exc:\n",
    "                        status_label.value = _format_status_html(f\"Auto-refresh failed: {exc}\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    except Exception as exc:\n",
    "                        status_label.value = _format_status_html(f\"Error: {exc}\", ok=False)\n",
    "                        _stop_artifact_poll()\n",
    "                        return\n",
    "                    _render_artifacts(payload)\n",
    "                    status_label.value = _format_status_html(\"Auto-refresh OK.\", ok=True)\n",
    "                    interval = max(2.0, float(interval_input.value or 4.0))\n",
    "                    await asyncio.sleep(interval)\n",
    "        except asyncio.CancelledError:\n",
    "            status_label.value = _format_status_html(\"Auto-refresh stopped.\", ok=True)\n",
    "\n",
    "    _stop_artifact_poll(from_toggle=True)\n",
    "    artifact_viewer_state[\"task\"] = loop.create_task(_poll())\n",
    "\n",
    "\n",
    "run_id_input = widgets.Text(\n",
    "    value=_artifact_viewer_run_id(),\n",
    "    description=\"Run ID\",\n",
    "    placeholder=\"production run id\",\n",
    "    layout=widgets.Layout(width=\"50%\"),\n",
    ")\n",
    "stage_input = widgets.Text(\n",
    "    description=\"Stage\",\n",
    "    placeholder=\"Optional stage (e.g., qa_publish)\",\n",
    "    layout=widgets.Layout(width=\"45%\"),\n",
    ")\n",
    "refresh_button = widgets.Button(description=\"Refresh\", icon=\"refresh\")\n",
    "auto_refresh_toggle = widgets.ToggleButton(description=\"Auto-refresh\", icon=\"repeat\", value=False)\n",
    "interval_input = widgets.BoundedFloatText(value=4.0, min=2.0, max=60.0, step=1.0, description=\"Interval (s)\")\n",
    "status_label = widgets.HTML(value=_format_status_html(\"Idle\", ok=True))\n",
    "artifacts_output = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", min_height=\"160px\", max_height=\"360px\", overflow=\"auto\"))\n",
    "\n",
    "refresh_button.on_click(_handle_manual_refresh)\n",
    "auto_refresh_toggle.observe(_handle_auto_toggle, names=\"value\")\n",
    "\n",
    "controls_row_1 = widgets.HBox([run_id_input, stage_input])\n",
    "controls_row_2 = widgets.HBox([refresh_button, auto_refresh_toggle, interval_input, status_label])\n",
    "artifacts_viewer_panel = widgets.VBox([controls_row_1, controls_row_2, artifacts_output])\n",
    "\n",
    "display(artifacts_viewer_panel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9d3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts viewer run_id now: run_68de8afd3a69\n"
     ]
    }
   ],
   "source": [
    "# Sync artifacts viewer Run ID widget with control panel\n",
    "if \"control_panel\" in globals() and hasattr(control_panel, \"run_id_input\"):\n",
    "    run_id_input.value = control_panel.run_id_input.value\n",
    "print(\"Artifacts viewer run_id now:\", run_id_input.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cdbbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts viewer manual refresh invoked.\n"
     ]
    }
   ],
   "source": [
    "# Trigger a manual artifacts refresh for verification logs\n",
    "_handle_manual_refresh(None)\n",
    "print(\"Artifacts viewer manual refresh invoked.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e2e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"run_id\": \"run_68de8afd3a69\",\n",
      "  \"artifact_count\": 22,\n",
      "  \"stages\": [\n",
      "    \"plan_intake\",\n",
      "    \"qa_base_images\",\n",
      "    \"qa_video\",\n",
      "    \"assemble\",\n",
      "    \"qa_publish\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Capture artifacts payload for notebook log (single fetch)\n",
    "import json\n",
    "current_run = run_id_input.value.strip() or _artifact_viewer_run_id()\n",
    "payload_snapshot = _fetch_artifacts_sync(current_run, stage_input.value.strip())\n",
    "stage_names = []\n",
    "for stage in payload_snapshot.get(\"stages\", []):\n",
    "    stage_names.append(stage.get(\"stage\") or stage.get(\"stage_id\"))\n",
    "print(json.dumps(\n",
    "    {\n",
    "        \"run_id\": current_run,\n",
    "        \"artifact_count\": len(list(_iter_artifacts(payload_snapshot))),\n",
    "        \"stages\": stage_names,\n",
    "    },\n",
    "    indent=2,\n",
    "    ensure_ascii=False,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de9b1a",
   "metadata": {},
   "source": [
    "## Optional: run a stub orchestration smoke test\n",
    "This cell runs the Python runner in simulation mode (fallback adapters) so you can confirm Drive folders are writable before enabling real models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Optional orchestrator smoke run (uses fallback adapters)\n",
    "import importlib.util\n",
    "from sparkle_motion.orchestrator import Runner\n",
    "in_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
    "if in_colab:\n",
    "    runs_root = Path(MOUNT_POINT) / \"MyDrive\" / WORKSPACE_NAME / \"runs\"\n",
    "else:\n",
    "    runs_root = REPO_ROOT / \"runs\"\n",
    "runs_root.mkdir(parents=True, exist_ok=True)\n",
    "movie_plan = {\n",
    "    \"title\": \"Colab Smoke\",\n",
    "    \"shots\": [\n",
    "        {\n",
    "            \"id\": \"shot_001\",\n",
    "            \"visual_description\": \"Test scene\",\n",
    "            \"duration_sec\": 2.0,\n",
    "            \"dialogue\": [{\"character\": \"narrator\", \"text\": \"Hello from Colab\"}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "runner = Runner(runs_root=str(runs_root))\n",
    "asset_refs = runner.run(movie_plan=movie_plan, run_id=\"colab_smoke\", resume=True)\n",
    "print(\"Smoke run complete. Final asset refs keys:\", asset_refs.keys())\n",
    "print(\"Runs directory:\", runs_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkle_motion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
